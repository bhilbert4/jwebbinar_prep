{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# Imaging Mode Data Calibration: Part 1 - Ramps to Slopes\n",
    "---\n",
    "**Author**: Bryan Hilbert (hilbert@stsci.edu)| **Latest Update**:5 April 2021\n",
    "\n",
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "* [Pipeline Resources and Documentation](#resources)\n",
    "   * [Installation](#installation)\n",
    "   * [Reference Files](#reference_files)\n",
    "* [Imports](#imports)\n",
    "* [Convenience Functions](#convenience_functions)\n",
    "* [Download Data](#download_data)\n",
    "* [Methods for calling steps/pipelines](#calling_methods)\n",
    "   * [run() method](#run_method)\n",
    "   * [Parameter reference files](#parameter_reffiles)\n",
    "   * [call() method](#call_method)\n",
    "   * [command line](#command_line)\n",
    "* [calwebb_detector1 - Ramps to slopes](#detector1) \n",
    "   * [Run the entire pipeline](#detector1_at_once)\n",
    "   * [Run the individual pipeline steps](#detector1_step_by_step)\n",
    "       * [The `Group Scale` step](#groupscale)\n",
    "       * [The `Data Quality Initialization` step](#dq_init)\n",
    "       * [The `Saturation Flagging` step](#saturation)\n",
    "       * [The `Superbias Subtraction` step](#superbias)\n",
    "       * [The `Reference Pixel Subtraction` step](#refpix)\n",
    "       * [The `Linearity Correction` step](#linearity)\n",
    "       * [The `Persistence Correction` step](#persistence)\n",
    "       * [The `Dark Current Subtraction` step](#dc)\n",
    "       * [The `Cosmic Ray Flagging` step](#jump)\n",
    "       * [The `Ramp_Fitting` step](#ramp_fitting)\n",
    "       * [The `Gain Scale` step](#gain_scale)\n",
    "* [Exercises](#exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "This notebook covers part 1 of the imaging mode data calibration module. In this notebook we'll review Stage 1 of the JWST calibration pipeline, also known as *calwebb_detector1*. \n",
    "\n",
    "The [Stage 1 pipeline](https://jwst-pipeline.readthedocs.io/en/stable/jwst/pipeline/calwebb_detector1.html#calwebb-detector1) applies basic detector-level corrections to all exposure types (imaging, spectroscopic, coronagraphic, etc.). It is applied to one exposure at a time, beginning with an uncalibrated multiaccum ramp (*_uncal.fits file*). It is sometimes referred to as “ramps-to-slopes” processing. The input raw data are in the form of one or more ramps (integrations) containing accumulating counts from the non-destructive detector readouts. The output is a corrected but uncalibrated countrate or slope image (*_rate.fits and _rateints.fits file*).\n",
    "\n",
    "To illustrate how the steps of the pipeline change the input data, we will download a sample file and run it through the pipeline, examining the results at several places along the way.\n",
    "\n",
    "All JWST data, regardless of instrument and observing mode, are processed through the Stage 1 pipeline. The corrections performed are the same across all near-IR instruments. There are several additional MIRI-specific steps. For the purposes of this notebook, our example file will be NIRCam data. We will also provide an example MIRI file that can be used in a separate exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='resources'></a>\n",
    "## Pipeline Resources and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit the [webpage for JWebbinars](https://www.stsci.edu/jwst/science-execution/jwebbinars) to find resources for:\n",
    "\n",
    "* JWST Documentation (JDox) for the Stage 1 pipeline\n",
    "* Additional documentation about the pipeline and pipeline stages in readthedocs\n",
    "\n",
    "\n",
    "\n",
    "There are several different places to find information on installing and running the pipeline. This notebook will give a shortened description of the steps pulled from the detailed pipeline information pages, but to find more in-depth instructions use the links below.\n",
    "\n",
    "\n",
    "* [`jwst` package GitHub repository, with installation instructions](https://github.com/spacetelescope/jwst/blob/master/README.md)\n",
    "* [`jwst` package documentation](https://jwst-pipeline.readthedocs.io/en/latest/jwst/introduction.html)\n",
    "* [Help Desk](https://stsci.service-now.com/jwst?id=sc_cat_item&sys_id=27a8af2fdbf2220033b55dd5ce9619cd&sysparm_category=e15706fc0a0a0aa7007fc21e1ab70c2f): If you have any questions or problems regarding the pipeline, submit a ticket to the Help Desk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='installation'></a>\n",
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `jwst` package on GitHub is where all the code for the JWST calibration pipeline lives.\n",
    "\n",
    "For this JWebbinar, we will be working in a pre-existing environment where the `jwst` package has already been installed. If you wish to run this notebook outside of this JWebbinar, you will have to install the `jwst` package. \n",
    "\n",
    "For detailed installation instructions, see the [installation instructions](https://github.com/spacetelescope/jwst/blob/master/README.md) on GitHub.\n",
    "\n",
    "The easiest way to install the pipeline is via `pip`. Below we show how to create a new conda environment, activate that environment, and then install the latest released version of the pipeline. You can name your environment anything you like. In the lines below, replace <env_name> with your chosen environment name.\n",
    "\n",
    ">`conda create -n <env_name> python`<br>\n",
    ">`conda activate <env_name>`<br>\n",
    ">`pip install jwst`\n",
    "\n",
    "If you wish to install the development version of the pipeline, which is more recent than (but not as well tested compared to) the latest released version:\n",
    "\n",
    ">`conda create -n <env_name> python`<br>\n",
    ">`conda activate <env_name>`<br>\n",
    ">`pip install git+https://github.com/spacetelescope/jwst`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reference_files'></a>\n",
    "### Reference Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we recommend having a local cache of Calibration Reference Data System (CRDS) reference files to use when running the pipeline. To enable that, there are two environment variables that should be set prior to calling the pipeline. These are the CRDS_PATH and CRDS_SERVER_URL variables. In the example below, reference files will be downloaded to the \"crds_cache\" directory under the home directory.\n",
    "\n",
    ">`$ export CRDS_PATH=$HOME/crds_cache`<br>\n",
    ">`$ export CRDS_SERVER_URL=https://jwst-crds.stsci.edu`\n",
    "\n",
    "The first time you invoke the pipeline, the CRDS server should download all of the context and reference files that are needed for that pipeline run, and dump them into the CRDS_PATH directory. Subsequent executions of the pipeline will first look to see if it has what it needs in CRDS_PATH and anything it doesn't have will be downloaded from the STScI cache. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">NOTE: Users at STScI should automatically have access to the Calibration Reference Data System (CRDS) cache for running the pipeline, and can skip setting these environment variables.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages necessary for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module with functions to get information about objects:\n",
    "import asdf\n",
    "import copy\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Numpy library:\n",
    "import numpy as np\n",
    "\n",
    "# For downloading data\n",
    "import requests\n",
    "\n",
    "# Astropy tools:\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import ImageNormalize, ManualInterval, LogStretch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up matplotlib for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "# %matplotlib inline\n",
    "\n",
    "# Use this version if you want interactive plots\n",
    "%matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import JWST pipeline-related modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible data quality flags\n",
    "from jwst.datamodels import dqflags\n",
    "\n",
    "# The entire calwebb_detector1 pipeline\n",
    "from jwst.pipeline import calwebb_detector1\n",
    "\n",
    "# Individual steps that make up calwebb_detector1\n",
    "from jwst.group_scale import GroupScaleStep\n",
    "from jwst.dq_init import DQInitStep\n",
    "from jwst.saturation import SaturationStep\n",
    "from jwst.superbias import SuperBiasStep\n",
    "from jwst.ipc import IPCStep                                                                                    \n",
    "from jwst.refpix import RefPixStep                                                                \n",
    "from jwst.linearity import LinearityStep\n",
    "from jwst.dark_current import DarkCurrentStep\n",
    "from jwst.jump import JumpStep\n",
    "from jwst.ramp_fitting import RampFitStep\n",
    "from jwst.gain_scale import GainScaleStep\n",
    "from jwst import datamodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which version of the pipeline we are running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwst\n",
    "print(jwst.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='convenience_functions'></a>\n",
    "## Define convenience functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some functions and some parameters that we will use repeatedly throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our working directory. Files created while running this notebook\n",
    "# will be saved in subdirectories under this location.\n",
    "base_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files created or downloaded in this notebook will be saved\n",
    "# in a subdirectory of the base directory called `Stage1`\n",
    "output_dir = os.path.abspath(os.path.join(base_dir, 'Stage1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the output directory exists before downloading any data\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, output_dir):\n",
    "    \"\"\"Download into the current working directory the\n",
    "    file from Box given the direct URL\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL to the file to be downloaded\n",
    "        \n",
    "    output_dir : str\n",
    "        Directory into which the file is downloaded\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    download_filename : str\n",
    "        Name of the downloaded file\n",
    "    \"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(\"Wrong URL - {}\".format(url))\n",
    "    download_basename = response.headers['Content-Disposition'].split('\"')[1]\n",
    "    print('Downloading {}...'.format(download_basename))\n",
    "    with open(download_basename, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                \n",
    "    download_filename = os.path.join(output_dir, download_basename)\n",
    "    shutil.move(download_basename, download_filename)\n",
    "    return download_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_jump(signal, jump_group, xpixel=None, ypixel=None, slope=None):\n",
    "    \"\"\"Function to generate the ramp for pixel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : numpy.ndarray\n",
    "        1D array of signal values\n",
    "        \n",
    "    jump_group : list\n",
    "        List of boolean values whether a jump is present or\n",
    "        not in each group\n",
    "        \n",
    "    slope : numpy.ndarray\n",
    "        1D array of signal values constructed from the slope\n",
    "    \"\"\"\n",
    "    groups = np.arange(len(signal))\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    plt.plot(groups, signal, marker='o', color='black')\n",
    "    plt.plot(groups[jump_group], signal[jump_group], marker='o', color='red',\n",
    "             label='Flagged Jump')\n",
    "    \n",
    "    if slope is not None:\n",
    "        plt.plot(groups, slope, marker='o', color='blue', label='Data from slope')\n",
    "        \n",
    "    plt.legend(loc=2)\n",
    "\n",
    "    plt.xlabel('Groups')\n",
    "    plt.ylabel('Signal (DN)')\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    \n",
    "    if xpixel and ypixel:\n",
    "        plt.title('Pixel ('+str(xpixel)+','+str(ypixel)+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_jumps(signals, jump_groups, pixel_loc, slopes=None):\n",
    "    \"\"\"Function to plot the ramp and show the jump location\n",
    "    for several pixels. For simplicity, let's force the input\n",
    "    number of pixels to be a square. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signals : numpy.ndarray\n",
    "        2D array (groups x pix) of signal values\n",
    "        \n",
    "    jump_groups : numpy.ndarray\n",
    "        2D array containing boolean entries for each group of\n",
    "        each pixel, describing where the jumps were found\n",
    "        \n",
    "    pixel_loc : list\n",
    "        List of 2-tuples containing the (x, y)\n",
    "        location of the pixels with the jumps\n",
    "        \n",
    "    slopes : numpy.ndarray\n",
    "        2D array (groups x pix) of linear signal values\n",
    "        If not None, these will be overplotted onto the\n",
    "        plots of signals\n",
    "    \"\"\"\n",
    "    num_group, num_pix = signals.shape\n",
    "    root = np.sqrt(num_pix)\n",
    "    if int(root + 0.5) ** 2 != num_pix:\n",
    "        raise ValueError('Number of pixels input should be a square.')\n",
    "    \n",
    "    root = int(root)\n",
    "    groups = np.arange(num_group)\n",
    "    fig, axs = plt.subplots(root, root, figsize=(10, 10))\n",
    "\n",
    "    for index in range(len(pixel_loc)):\n",
    "        i = int(index % root)\n",
    "        j = int(index / root)\n",
    "        axs[i, j].plot(groups, signals[:, index], marker='o', color='black')\n",
    "        j_grp = jump_groups[:, index]\n",
    "        axs[i, j].plot(groups[j_grp], signals[j_grp, index],\n",
    "                       marker='o', color='red')\n",
    "        \n",
    "        if slopes is not None:\n",
    "            axs[i, j].plot(groups, slopes[:, index], marker='o', color='blue')\n",
    "        \n",
    "        axs[i, j].set_title('Pixel ({}, {})'.format(pixel_loc[index][1], pixel_loc[index][0]))\n",
    "        \n",
    "    plt.xlabel('Groups')\n",
    "    plt.ylabel('Signal (DN)')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ramp(groups, signal, xpixel=None, ypixel=None, title=None):\n",
    "    \"\"\"Function to generate the ramp for pixel.\n",
    "    \"\"\"    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "    if xpixel and ypixel:\n",
    "            plt.plot(groups, signal, marker='o',\n",
    "                     label='Pixel ('+str(xpixel)+','+str(ypixel)+')') \n",
    "            plt.legend(loc=2)\n",
    "\n",
    "    else:\n",
    "        plt.plot(groups, signal, marker='o')\n",
    "        \n",
    "    plt.xlabel('Groups')\n",
    "    plt.ylabel('Signal (DN)')\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ramps(groups, signal1, signal2, label1=None, label2=None, title=None):\n",
    "    \"\"\"Function to generate the ramp for pixel.\n",
    "    \"\"\"    \n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = plt.subplot()\n",
    "    if label1:\n",
    "        plt.plot(groups, signal1, marker='o', color='black', label=label1)\n",
    "    else:\n",
    "        plt.plot(groups, signal1, marker='o', color='black')\n",
    "    if label2:\n",
    "        plt.plot(groups, signal2, marker='o', color='red', label=label2)\n",
    "    else:\n",
    "        plt.plot(groups, signal2, marker='o', color='red')\n",
    "    if label1 or label2:\n",
    "        plt.legend(loc=2)\n",
    "        \n",
    "    plt.xlabel('Groups')\n",
    "    plt.ylabel('Signal (DN)')\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data_2d, vmin, vmax, xpixel=None, ypixel=None, title=None):\n",
    "    \"\"\"Function to generate a 2D, log-scaled image of the data, \n",
    "    with an option to highlight a specific pixel.\n",
    "    \"\"\"\n",
    "    norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                          stretch=LogStretch())\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    im = ax.imshow(data_2d, origin='lower', norm=norm)\n",
    "    \n",
    "    if xpixel and ypixel:\n",
    "        plt.plot(xpixel, ypixel, marker='o', color='red', label='Selected Pixel')\n",
    "\n",
    "    fig.colorbar(im, label='DN')\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_by_side(data1, data2, vmin, vmax, xpixel=None, ypixel=None, title1=None,\n",
    "                 title2=None,title=None):\n",
    "    \"\"\"Show two images side by side for easy comparison\n",
    "    \"\"\"\n",
    "    norm = ImageNormalize(data1, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                          stretch=LogStretch())\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(11, 8))\n",
    "    im = axes[0].imshow(data1, origin='lower', norm=norm)\n",
    "    im = axes[1].imshow(data2, origin='lower', norm=norm)\n",
    "    \n",
    "    axes[0].set_xlabel('Pixel column')\n",
    "    axes[0].set_ylabel('Pixel row')\n",
    "    axes[1].set_xlabel('Pixel column')\n",
    "    \n",
    "    if title1:\n",
    "        axes[0].set_title(title1)\n",
    "    if title2:\n",
    "        axes[1].set_title(title2)\n",
    "    \n",
    "    # Highlight a pixel if requested\n",
    "    if xpixel and ypixel:\n",
    "        plt.plot(xpixel, ypixel, marker='o', color='red', label='Selected Pixel')\n",
    "        \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax, label='DN')\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='download_data'></a>\n",
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this module, we will use an uncalibrated NIRCam simulated imaging exposure that is stored in Box. Let's grab it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_url = 'https://stsci.box.com/shared/static/mbt33pgin5psn6ayz6zmgwhpz3rmsqu4.fits'\n",
    "uncal_file = download_file(uncal_url, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download example parameter reference files\n",
    "det_param_reffile_url = 'https://stsci.box.com/shared/static/nmaipgvlferrz95eyksra4zmlhx2m5bm.asdf'\n",
    "detector1_param_reffile = download_file(det_param_reffile_url, output_dir)\n",
    "\n",
    "refpix_param_reffile_url = 'https://stsci.box.com/shared/static/kww0o8d77h2u03b38gtdr34g8vqygx8w.asdf'\n",
    "refpix_param_reffile = download_file(refpix_param_reffile_url, output_dir)\n",
    "\n",
    "refpix_param_reffile_no_side_pix_url = 'https://stsci.box.com/shared/static/c95paaz9gsvrwwo3slx8k9qav242idi1.asdf'\n",
    "refpix_param_reffile_no_side_pix = download_file(refpix_param_reffile_no_side_pix_url, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also download the example MIRI file if you wish to try the exercise of running it through the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASK THE MIRI TEAM FOR SOME S?IMULATED FILES....\n",
    "miri_uncal_url = ''\n",
    "# miri_uncal_file = download_file(miri_uncal_url, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='calling_methods'></a>\n",
    "## Methods for calling steps/pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three common methods by which the pipeline or pipeline steps can be called. From within python, the `run()` and `call()` methods of the pipelne or step classes can be used. Alternatively, the `strun` command can be used from the command line. When using the `call()` method or `strun`, optional input parameters can be specified via [configuration files](#parameter_reffiles). When using the `run()` method, these parameters are instead specified within python. \n",
    "\n",
    "Below, where we [call the entire pipeline](#detector1_at_once), as well as the section where we [call the Reference Pixel Subtraction](#refpix) step, we show examples of all three methods. For the remainder of the pipeline steps, we will focus on using the `run()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run_method'></a>\n",
    "### Run() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the `run()` method to execute a pipeline (or step), the pipeline class is first instantiated without the data to be processed. Optional input parameters are specified using attributes of the class instance. Finally, the call to the `run()` method is made and the data are supplied.  See here for [example usage of run() method](https://jwst-pipeline.readthedocs.io/en/stable/jwst/stpipe/call_via_run.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameter_reffiles'></a>\n",
    "### Parameter Reference Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling a pipeline or pipeline step using the `call()` method or the command line, [parameter reference files](https://jwst-pipeline.readthedocs.io/en/stable/jwst/stpipe/config_asdf.html#config-asdf-files) can be used to specify values for input parameters. These reference files are [asdf](https://asdf.readthedocs.io/en/stable/) format and appear somewhat similar to json files when examined in a text editor. \n",
    "\n",
    "Versions of parameter reference files containing default parameter values for each step and pipeline are present in CRDS. When using the `call()` method, if you do not specify a parameter reference file name in the call, the pipeline or step will use the appropriate file from CRDS. When using `strun`, the parameter reference file is a required input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='call_method'></a>\n",
    "### call() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the `call()` method to execute a pipeline (or step), the input data and optional paramter reference files are supplied to the pipeline class when it is instantiated. In this case, any desired input parameters must be set in the parameter reference files. They cannot be set after instantiation, as with the `run()` method. See here for [example usage of call() method](https://jwst-pipeline.readthedocs.io/en/stable/jwst/stpipe/call_via_call.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='command_line'></a>\n",
    "### Command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling a pipeline, or step, from the command line is similar to using the `call()` method. Parameter reference files and the data file to be processed are provided to the `strun` command. All desired input paramter values must be specified within the parameter reference files. See here for [example usage of command line calls](https://jwst-pipeline.readthedocs.io/en/stable/jwst/introduction.html?highlight=%22command%20line%22#running-from-the-command-line)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='detector1'></a>\n",
    "## The calwebb_detector1 pipeline: Ramps to slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sections below, we will run the Stage 1 pipeline on a single uncalibrated NIRCam file. We will first call the entire *calwebb_detector1* pipeline on the file. The pipeline is a wrapper which will string together all of the appropriate steps in the proper order. The final output from this call is an uncalibrated slope image which is ready to go into the Stage 2 pipeline.\n",
    "\n",
    "After that, we will go back to the original uncalibrated ramp and manually run it through each of the steps that comprise the Stage 1 pipeline. For each step we will describe in more detail what is going on, and for several of the more interesting steps, we will examine the output.\n",
    "\n",
    "See [Figure 1](https://jwst-docs.stsci.edu/jwst-data-reduction-pipeline/algorithm-documentation/stages-of-processing/calwebb_detector1) on the calwebb_detector1 algorithm page for a map of which steps are performed on NIR data and which are used for MIRI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_base = os.path.basename(uncal_file).replace('uncal.fits', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='detector1_at_once'></a>\n",
    "### Run the entire `calwebb_detecor1` pipeline\n",
    "\n",
    "In this section we show how to run the entire calwebb_detector1 pipeline with a single call. In this case the pipeline code can determine which instrument was used to collect the data and runs the appropriate steps in the proper order.\n",
    "\n",
    "We show all three methods for calling the pipeline.\n",
    "\n",
    "\n",
    "We set parameter values for some of the individual steps, save some outputs, etc, and then call the pipeline.\n",
    "\n",
    "[Pipeline output suffixes](https://jwst-pipeline.readthedocs.io/en/stable/jwst/introduction.html#pipeline-step-suffix-definitions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detector1_output_file = '{}_rate.fits'.format(input_file_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the run() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an instance of the pipeline class\n",
    "detector1 = calwebb_detector1.Detector1Pipeline()\n",
    "\n",
    "# Set some parameters that pertain to the\n",
    "# entire pipeline\n",
    "detector1.output_dir = output_dir\n",
    "detector1.save_results = True\n",
    "\n",
    "# Set some parameters that pertain to some of\n",
    "# the individual steps\n",
    "detector1.refpix.use_side_ref_pix = True\n",
    "detector1.linearity.save_results = True\n",
    "detector1.jump.rejection_threshold = 6\n",
    "\n",
    "# Call the run() method\n",
    "run_output = detector1.run(uncal_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the call() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we'll supply a parameter reference file to the pipeline call. Let's look at what's in that file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det1_reffile = asdf.open(detector1_param_reffile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top part of the file contains various metadata entries about the file itself. Below that, you'll see a `'name'` entry, which lists `Detector1Pipeline` as the class to which these parameters apply. The next line contains the `parameters` entry, which lists parameters and values attached to the pipeline itself. Below this is the `steps` entry, which contains a list of dictionaries. Each dictionary refers to one step within the pipeline, and specifies parameters and values that apply to that step. If you look through these entries, you'll see the same parameters and values that we specified manually when using the `run()` method above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det1_reffile.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the pipeline using the `call()` method and supply the parameter reference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# At instantiation, provide the name of the \n",
    "# observation file, the pipeline-specific input\n",
    "# paramters, and the name of the parameter reference\n",
    "# files that specify step-specific parameters\n",
    "\n",
    "call_output = calwebb_detector1.Detector1Pipeline.call(uncal_file,\n",
    "                                                       output_dir=output_dir,\n",
    "                                                       save_results=True,\n",
    "                                                       config_file=detector1_param_reffile)\n",
    "\n",
    "# Here is another way to use the call() method. In this case,\n",
    "# you build a nested dictionary that specifies parameter values\n",
    "# for various steps, and provide it in the call to call().\n",
    "\n",
    "#parameter_dict = {\"refpix\": {\"use_side_ref_pix\": True},\n",
    "#                  \"linearity\": {\"save_results\": True},\n",
    "#                  \"jump\": {\"rejection_threshold\": 6},\n",
    "#                 }\n",
    "#call_output = Detector1Pipeline.call(uncal_file, output_dir=output_dir, save_results=True,\n",
    "#                                     config_file='', steps=parameter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make sure that this works, but dont call it during the webbinar. no sense in having people wait through\n",
    "multiple pipeline calls on the same file\n",
    "\n",
    "# Similar to the use of the call() method above, we\n",
    "# provide the name of the observation file, pipeline-\n",
    "# specific parameters, and the names of step-specific\n",
    "# parameter reference files.\n",
    "\n",
    "need param reffile option here...\n",
    "\n",
    "# Remember that this must be run on the command line,\n",
    "# rather than in this notebook\n",
    "# strun jwst.pipeline.Detector1Pipeline <uncal_filename> --steps.refpix.use_side_ref_pix=True --steps.linearity.save_results=True --steps.jump.rejection_threshold=6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary output of the calwebb_detector1 pipeline is a file containing a rate image for the exposure. The units of the data are ADU/sec.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_file = uncal_file.replace('uncal.fits', 'rate.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_data = fits.getdata(rate_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(rate_data, 0.5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, since we set the linearity step's `save_results` parameter to True in our calls above, the pipeline saved the output of the linearity step. In this case, the output file will have the same name as the input uncal file, but with the suffix 'linearity' rather than 'uncal'. \n",
    "\n",
    "**NOTE:** This differs slightly from the case where we call the linearity step itself and save the results. In that case, as we will see in the [linearity](#linearity) section, the output file will have the suffix 'linearitystep' rather than 'linearty'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_file = rate_file.replace('rate.fits', 'linearity.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_data = fits.getdata(linear_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look in more detail at the effects of the linearity correction step in the [linearity](#linearity) section below. For now, let's just look at the final group of the integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the data in the final group of the linearized data:\n",
    "show_image(lin_data[0, -1, :, :], 100, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='detector1_step_by_step'></a>\n",
    "## Run the individual pipeline steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sections below we run the steps contained within calwebb_detector1 one at a time, in order to more clearly see what each step is doing. Since our example data are from NIRCam, we will skip the MIRI-specific steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='groupscale'></a>\n",
    "### The `Group Scale` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step rescales pixel values in the raw JWST science products in cases where multiple [frames](https://jwst-docs.stsci.edu/understanding-exposure-times#UnderstandingExposureTimes-uptherampHowup-the-rampreadoutswork) were averaged on-board to create the [groups](https://jwst-docs.stsci.edu/understanding-exposure-times#UnderstandingExposureTimes-uptherampHowup-the-rampreadoutswork) in the multiaccum ramp, but the number of frames per group is not a power of 2. This occurs primarily in [NIRSpec IRS^2 data that uses the NRSIRS2 readout pattern (see Table 1)](https://jwst-docs.stsci.edu/near-infrared-spectrograph/nirspec-instrumentation/nirspec-detectors/nirspec-detector-readout-modes-and-patterns) data. Data with no frame averaging, or where the number of frames is a power of 2, will not be affected by this step. See Figure 2 in the [NIRCam detector readout](https://jwst-docs.stsci.edu/near-infrared-camera/nircam-instrumentation/nircam-detector-overview/nircam-detector-readout-patterns) page for some examples of readout patterns where multiple frames are averaged to create each group.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/group_scale/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step does not use any reference files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, since we have NIRCam data, the step will be skipped. Let's try running it just to show that it is indeed skipped, and the data are not changed at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the run() method\n",
    "group_scale_step = GroupScaleStep()\n",
    "group_scale_step.output_dir = output_dir\n",
    "group_scale_step.save_results = True\n",
    "group_scale = group_scale_step.run(uncal_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the output is saved, the group_scale step will\n",
    "# attach a suffix of 'group_scale' to the input filename.\n",
    "group_scale_output_file = os.path.join(output_dir, '{}groupscalestep.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the NIRCam data we are using, there is no frame-averaging done to produce the groups, so the group_scale step does not change the data in any way. Let's move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Move this cell and the cell below to a step where the header is changed, such as assign_wcs or flux_cal\n",
    "\n",
    "**Indeed, the step does not do anything. Both outputs are exactly equal, as expected**. What about the headers? To check this out, let's use `fits.HeaderDiff`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fits.HeaderDiff(hdul['SCI'].header, hdul_group_scale['SCI'].header)\n",
    "results.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dq_init'></a>\n",
    "### The `Data Quality Initialization` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step populates the Data Quality (DQ) mask that is associated with the data file. The DQ flags from the `MASK` reference file are copied into the `PIXELDQ` extension of the input file. A table showing the [mapping of bit values](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/references_general.html#data-quality-flags) in the `MASK` file decribes what types of bad pixels can be flagged. Any other bad pixel types will be ignored.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/dq_init/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the `MASK` reference file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the run() method\n",
    "dq_init_step = DQInitStep()\n",
    "dq_init_step.output_dir = output_dir\n",
    "dq_init_step.save_results = True\n",
    "\n",
    "# Note that the run() method can be called on EITHER:\n",
    "# the datamodel instance output from the group_scale\n",
    "# step.\n",
    "dq_init = dq_init_step.run(group_scale)\n",
    "\n",
    "# OR:\n",
    "# the fits file containing the group_scale output\n",
    "#dq_init = dq_init_step.run(group_scale_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step finished without crashing, but as it is said above, there are some errors and warnings worth noting:\n",
    "1. `NOISY` and `WEIRD` do not correspond to existing `DQ` mnemonics, so they are ignored (this is normal, see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values in the `SCI` extension are not changed in this step. Instead, the DQ flags are copied into the `PIXELDQ` extension. The `GROUPDQ` values are not changed in this step. Let's check the `PIXELDQ` values and see what has changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the datamodel instance of the output available already, but if you wanted to open the output file from the data quality initiailzation step, the output file has the same name as the input file, with the original suffix replaced by \"dqinitstep\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq_init_output_file = os.path.join(output_dir, '{}dqinitstep.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_scale_pixeldq = group_scale.pixeldq\n",
    "dq_init_pixeldq = dq_init.pixeldq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_pixelDQ = dq_init_pixeldq - group_scale_pixeldq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_pixelDQ = np.where(difference_pixelDQ.flatten() == 0.)[0]\n",
    "print('Total pixels in PIXELDQ: {}'.format(difference_pixelDQ.size))\n",
    "print('{} pixels have no flags.'.format(len(idx_pixelDQ)))\n",
    "print('{} pixels have flags.'.format(difference_pixelDQ.size - len(idx_pixelDQ)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='saturation'></a>\n",
    "## The `Saturation Flagging` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step checks the signal values in all pixels across all groups, and adds a [`saturated` flag](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/references_general.html#data-quality-flags) to the `GROUPDQ` extension for pixels and groups where the signal is above the saturation limit.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/saturation/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`SATURATION`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/saturation/reference_files.html) reference file. This file contains a map of the saturation threshold in ADU for each pixel on the detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the run() method\n",
    "saturation_step = SaturationStep()\n",
    "saturation_step.output_dir = output_dir\n",
    "saturation_step.save_results = True\n",
    "\n",
    "saturation = saturation_step.run(dq_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any saturated values, they should appear in the `GROUPDQ` arrays. Let's examine the `GROUPDQ` data and see if there are any detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturated = np.where(saturation.groupdq & dqflags.pixel['SATURATED'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sat_flags = len(saturated[0])\n",
    "print(('Found {} saturated flags. This may include multiple saturated '\n",
    "       'groups within a given pixel'.format(num_sat_flags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find a pixel that saturated part of the way up the ramp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4D boolean map of whether the saturation flag is present or not.\n",
    "saturated = (saturation.groupdq & dqflags.pixel['SATURATED'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse that down to a 2D map that lists the number of saturated groups \n",
    "# for each pixel.\n",
    "saturated_2d = np.sum(saturated[0, :, :, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates of pixels that are saturated in some, but not all, groups.\n",
    "partial_sat = np.where((saturated_2d > 0) & (saturated_2d < saturated.shape[1]))\n",
    "print(\"{} pixels are partially saturated.\".format(len(partial_sat[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose one of these partially saturated pixels and look at the signal values up the ramp, along with which groups are flagged as saturated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_y, sat_x = partial_sat\n",
    "sat_index = 123\n",
    "y = sat_y[sat_index]\n",
    "x = sat_x[sat_index]\n",
    "grps = saturated[0, :, y, x]\n",
    "print('Saturation flags up the ramp (0 is not saturated, 2 is saturated): {}'\n",
    "      .format(saturation.groupdq[0, :, y, x]))\n",
    "print('Pixel signal values up the ramp: {}'.format(saturation.data[0, :, y, x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot these in order to get a clearer look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups = np.arange(saturation.data.shape[1])\n",
    "full_ramp = saturation.data[0, :, y, x]\n",
    "sat_dq = saturation.groupdq[0, :, y, x].astype(bool)\n",
    "saturated_points = copy.deepcopy(saturation.data[0, :, y, x])\n",
    "saturated_points[~sat_dq] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ramps(groups, full_ramp, saturated_points, label1='Not Saturated',\n",
    "           label2='Saturated', title='Pixel ({}, {})'.format(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id='superbias'> </a>\n",
    "## The `Superbias Subtraction` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step subtracts the superbias reference frame from each group of the science exposure.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/superbias/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`SUPERBIAS`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/superbias/reference_files.html) reference file. This file contains a map of the superbias signal in ADU for each pixel on the detector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using the run() method\n",
    "superbias_step = SuperBiasStep()\n",
    "superbias_step.output_dir = output_dir\n",
    "superbias_step.save_results = True\n",
    "\n",
    "superbias = superbias_step.run(saturation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare how the science products visually look like in comparison with the raw `uncal` data for the last group of the first integration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superbias_output_file = os.path.join(output_dir, '{}superbiasstep.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superbias_output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superbias.data[0, 0, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_by_side(saturation.data[0, 0, :, :], superbias.data[0, 0, :, :], vmin=10000, vmax=18000,\n",
    "            title1='Before superbias subtraction', title2='After superbias subtraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='refpix'></a>\n",
    "## The `Reference Pixel Subtraction` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step uses the reference pixels, which are not sensitive to illumination, to subtract group- and amplifier-dependent signal originating in the readout electronics from the data. There are two distinct corrections that are applied here.\n",
    "\n",
    "First, the rows of reference pixels on the top and bottom of the detector are used to subtract amplifier-dependent offsets from each group. Within a given amplifier, the mean value of all reference pixels in even numbered columns is subtracted from the science pixels in the even numbered columns. The same strategy is used for the odd numbered columns. \n",
    "\n",
    "The second part of the reference pixel subtraction step uses the reference pixels along the left and right sides of the detector to mitigate 1/f noise. This noise is visible in the data as horizontal banding that stretches across the entire detector. \n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/refpix/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "[Full details on the optional arguments](https://jwst-pipeline.readthedocs.io/en/stable/jwst/refpix/arguments.html).\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step does not use any reference files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better show the effects from the 2 parts of the reference file subtraction, we're going to run this step twice. First we'll perform only the mean value subtraction using the top and bottom reference pixels. Then on the second run, we'll perform both the mean value subtraction and the 1/f subtraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the run() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this 'partial' run, we need to turn off the 1/f correction that\n",
    "# uses the reference pixels on the sides of the detector. Also, we'll\n",
    "# save the output using a unique name so as not to confuse the file\n",
    "# with the output where we run the entire repix subtraction step.\n",
    "\n",
    "refpix_step_no_sidepix = RefPixStep()\n",
    "refpix_step_no_sidepix.output_dir = output_dir\n",
    "refpix_step_no_sidepix.save_results = True\n",
    "refpix_step_no_sidepix.output_file = 'refpix_test_no_side_pixels'\n",
    "\n",
    "# Turn off the 1/f correction\n",
    "refpix_step_no_sidepix.use_side_ref_pixels = False\n",
    "\n",
    "# Call using the saturation instance from the previously-run\n",
    "# saturation step\n",
    "refpix_no_sidepix = refpix_step_no_sidepix.run(superbias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run the full correction. This will produce the output that we will feed into subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refpix_step = RefPixStep()\n",
    "refpix_step.output_dir = output_dir\n",
    "refpix_step.save_results = True\n",
    "\n",
    "# Call using the saturation instance from the previously-run\n",
    "# saturation step\n",
    "refpix = refpix_step.run(superbias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the call() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will run the pipeline with the same parameters as the preceeding two cells, but using the `call()` method rather than the `run()` method. In this case we have a separate parameter reference file for each call. \n",
    "\n",
    "Let's look at the parameter referece files. The difference between the two is in the `use_side_ref_pixels` entry, on the bottom line of each. These files look fairly similar to that for the Detector1Pipeline. In this case, the step's parameters and values are all listed in the `parameters` entry of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_refpix_params = asdf.open(refpix_param_reffile)\n",
    "default_refpix_params.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_refpix_params = asdf.open(refpix_param_reffile_no_side_pix)\n",
    "default_refpix_params.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `call()` method and the parameter reference file with all of the default settings to run the refernce pixel subtraction step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refpix_output = RefPixStep.call(superbias, output_dir=output_dir,\n",
    "                                save_results=True, \n",
    "                                config_file=refpix_param_reffile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the reference pixel subtraction step again, but use the parameter reference file that has the side reference pixel step turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refpix_output_no_side_pix = RefPixStep.call(superbias, output_dir=output_dir,\n",
    "                                            output_file='refpix_test_no_side_pixels_via_call',\n",
    "                                            save_results=True, \n",
    "                                            config_file=refpix_param_reffile_no_side_pix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to examine the output file from this step, the file is saved with the \"refpixstep\" suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refpix_output_file = os.path.join(output_dir, '{}refpixstep.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the output from this step. As with all NIR detectors, the outermost 4 rows and columns comprise the reference pixels.\n",
    "\n",
    "Let's use the datamodels from before and after the reference pixel subtraction to have a look at the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll zoom in on the top few rows in order to see the changes. Note how the \"odd/even\" effect dominates the signal prior to reference pixel subtraction. Even numbered columns and odd numbered columns have significantly different signal levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_by_side(superbias.data[0, 5, 2030:, 1030:1050], refpix.data[0, 5, 2030:, 1030:1050],\n",
    "             vmin=0, vmax=30000, title1='Before Refpix Subtraction',\n",
    "             title2='After Refpix Subtraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_image(superbias.data[0, 5, 2030:, 1030:1050] - refpix.data[0, 5, 2030:, 1030:1050],\n",
    "           vmin=7000, vmax=16000, title='Difference: Before - After Refpix Subtraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the difference in the data after the mean value subtraction compared to the case where both the mean value subtraction and the 1/f correction are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_by_side(refpix_no_sidepix.data[0, 5, :, :], refpix.data[0, 5, :, :],\n",
    "             vmin=0, vmax=125, title1='No Side Repix Correction',\n",
    "             title2='With Side Refpix Correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linearity'></a>\n",
    "## The `Linearity Correction` step \n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step applies the classical linearity correction to the data on a pixel-by-pixel, integration-by-integration, group-by-group manner.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/linearity/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`LINEARITY`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/linearity/reference_files.html) reference file. This file contains the polynomial coefficients used to apply the linearity correction to non-linear data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the run() method\n",
    "linearity_step = LinearityStep()\n",
    "linearity_step.output_dir = output_dir\n",
    "linearity_step.save_results = True\n",
    "\n",
    "# Call using the refpix instance from the previously-run\n",
    "# refpix step\n",
    "linearity = linearity_step.run(refpix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output file from this step has the \"linearitystep\" suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearity_output_file = os.path.join(output_dir, '{}linearitystep.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the signal up the ramp for a high signal pixel, in order to more easily see how the linearity correction changed the data. First, identify all pixels with signal values between 40,000 and 60,000 DN in the final group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_exposed = np.where((linearity.data[0, -1, :, :] > 40000.) & (linearity.data[0, -1, :, :] < 60000.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} pixels meet the criteria above.'.format(len(well_exposed[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick one of these pixels and plot the signal before and after the linearity correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 100\n",
    "lin_pix_x, lin_pix_y = (well_exposed[1][index], well_exposed[0][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_nums = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ramps(group_nums, refpix.data[0, :, lin_pix_y, lin_pix_x],\n",
    "           linearity.data[0, :, lin_pix_y, lin_pix_x], label1='Uncorrected', label2='Corrected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the pixel reached saturation in group 5. So from group 5 onwards, the linearity correction made no changes. Between groups 0 to 4, you can see the original signal (in black) becoming more and more non-linear as signal increases, along with how the linearity correction modified the signal (red)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dc'></a>\n",
    "##  The `Dark Current Subtraction` step \n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step subtracts the dark current, group by group, from the input integrations.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/dark_current/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`DARK`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/dark_current/reference_files.html) reference file. This file contains the measured mean dark current associated with the detector and subarray.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the run() method\n",
    "dark_step = DarkCurrentStep()\n",
    "dark_step.output_dir = output_dir\n",
    "dark_step.save_results = True\n",
    "\n",
    "# Call using the linearity instance from the previously-run\n",
    "# linearity step\n",
    "dark = dark_step.run(linearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_output_file = os.path.join(output_dir, '{}darkcurrentstep.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='jump'></a>\n",
    "## The `Cosmic Ray Flagging` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step searches for \"jumps\" in the ramp data. In this case, a jump in a pixel's ramp is defined as a large deviation in the count rate relative to that in the other groups. When a jump is found, the associated flag is added to the `GROUPDQ` extension for the group and pixel where the jump was detected. The science data are not modified at all. In the subsequent ramp-fitting step, the algorithm will look into the `GROUPDQ` array and ignore any groups where the jump flag has been set.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/jump/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "The jump step has [several optional arguments](https://jwst-pipeline.readthedocs.io/en/stable/jwst/jump/arguments.html)\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`READNOISE`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/readnoise_reffile.html) and [`GAIN`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/gain_reffile.html) reference files. These files contain maps of the readnoise and gain values across the detector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the run() method\n",
    "jump_step = JumpStep()\n",
    "jump_step.output_dir = output_dir\n",
    "jump_step.save_results = True\n",
    "jump_step.rejection_threshold = 9\n",
    "\n",
    "# Call using the dark instance from the previously-run\n",
    "# dark current subtraction step\n",
    "jump = jump_step.run(dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_output_file = os.path.join(output_dir, '{}jumpstep.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what some of these jumps look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_flags = np.where(jump.groupdq & dqflags.pixel['JUMP_DET'] > 0)\n",
    "print('{} jump flags detected.'.format(len(jump_flags[0])))\n",
    "\n",
    "jump_map = (jump.groupdq & dqflags.pixel['JUMP_DET'] > 0)\n",
    "jump_map_2d = np.sum(jump_map[0, :, :, :], axis=0)\n",
    "jump_map_indexes = np.where(jump_map_2d > 0)\n",
    "#jump_map_indexes = np.where(jump.groupdq & dqflags.pixel['JUMP_DET'] > 0)\n",
    "#hits_per_pix = np.sum(jump_map[0, :, :, :], axis=0)\n",
    "impacted_pix = np.sum(jump_map_2d > 0)\n",
    "total_pix = 2048 * 2048\n",
    "print(('{} pixels ({:.2f}% of the detector) have been flagged with '\n",
    "      'at least one jump.'.format(impacted_pix, 100. * impacted_pix / total_pix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some of the pixels impacted by jumps. The red marks signify flagged jumps. These signal values will be ignored in subsequent ramp-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_indexes = np.arange(jump_map.shape[1]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_index = 10112\n",
    "jumpy = jump_map_indexes[0][j_index]\n",
    "jumpx = jump_map_indexes[1][j_index]\n",
    "jump_grp = jump_map[0, :, jumpy, jumpx]\n",
    "print('Jump located in group(s) {} of pixel ({}, {})'.format(group_indexes[jump_grp], jumpx, jumpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_jump(jump.data[0, :, jumpy, jumpx], jump_grp, xpixel=jumpx, ypixel=jumpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a grid of some examples of flagged jumps. The red marks signify flagged jumps. These signal values will be ignored in subsequent ramp-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_plot = [200, 400, 600, 30000, 31000, 1200, 1400, 21600, 10112]\n",
    "jump_data = np.zeros((jump.shape[1], len(indexes_to_plot)))\n",
    "jump_grps = np.zeros((jump.shape[1], len(indexes_to_plot))).astype(bool)\n",
    "jump_locs = []\n",
    "for counter, idx in enumerate(indexes_to_plot):\n",
    "    #integ, grp, y, x = jump_flags[idx]\n",
    "    y = jump_map_indexes[0][idx]\n",
    "    x = jump_map_indexes[1][idx]\n",
    "    grp = jump_map[0, :, y, x]\n",
    "\n",
    "    jump_data[:, counter] = jump.data[0, :, y, x]\n",
    "    jump_grps[:, counter] = grp\n",
    "    jump_locs.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_jumps(jump_data, jump_grps, jump_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ramp_fitting'></a>\n",
    "## The `Ramp Fitting` step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "This step performs line-fitting to the corrected data, and produces a slope image for each integration. For a given pixel, any groups within an integration that contain a jump flag or that are flagged as saturated are ignored.\n",
    "\n",
    "For the purposes of this notebook, we will use the `save_opt` parameter to tell the ramp-fitting step to save an optional output file that contains some of the details on the ramp fits. This information will be used for the plots after the step is run. By default, `save_opt` is False and the optional outputs are not saved.\n",
    "\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/ramp_fitting/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "The jump step has [several optional arguments](https://jwst-pipeline.readthedocs.io/en/stable/jwst/ramp_fitting/arguments.html), including the ability to save optional outputs into a second file.\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`READNOISE`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/readnoise_reffile.html) and [`GAIN`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/gain_reffile.html) reference files. These files contain maps of the readnoise and gain values across the detector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the run() method\n",
    "ramp_fit_step = RampFitStep()\n",
    "ramp_fit_step.output_dir = output_dir\n",
    "ramp_fit_step.save_results = True\n",
    "\n",
    "# Let's save the optional outputs, in order\n",
    "# to help with visualization later\n",
    "ramp_fit_step.save_opt = True\n",
    "\n",
    "# Call using the dark instance from the previously-run\n",
    "# dark current subtraction step\n",
    "ramp_fit = ramp_fit_step.run(jump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important detail here is that there are two output files: \n",
    "\n",
    "1. The file ending with `*_0_rampfitstep.fits` contains the mean rate image from all the integrations in the exposure.\n",
    "\n",
    "2. The file ending with `*_1_rampfitstep.fits` contains separate slope images for each integration. In this case our exposure contains only a single integration, so the data in the two files are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rampfit_output_file = os.path.join(output_dir, '{}_0_rampfitstep.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working with the output datamodels in this notebook. Unlike the preceeding steps, where the output was a single datamodel, the ramp_fitting step outputs a tuple of 2 datamodel instances. The first element in the tuple is the datamodel instance containing the mean rate image, while the second element is the datamodel instance containing a separate slope image for each integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ramp_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the shape of each element of the tuple. The case with the mean rate image is only 2-dimensional, while the case with one rate image for each integration is 3-dimensional, even in this case where we have only one integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramp_fit[0].shape, ramp_fit[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that in our case with a single integration, the two datamodel instances contain identical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramp_fit[0].data[500, 500], ramp_fit[1].data[0, 500, 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data from the third output file, which contains the optional outputs. Our goal is to grab the intercept values from the line-fitting and use them to re-create the plots from the jump step and overplot the best-fit signals on top of the signals that went into the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optional_file = os.path.join(output_dir, '{}fitopt.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist = fits.open(optional_file)\n",
    "hdulist.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercepts from the line-fitting are stored in the `YINT` extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist['YINT'].data[0, :, 200, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our plots below, we need the intercept values from the line-fitting. Let's ignore all but the first plane of the extension, since those are zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = hdulist['YINT'].data[0, 0, :, :]\n",
    "hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the pixels to be plotted, create linear ramps using the output slopes and intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the exposure time associated with each group\n",
    "num_groups = ramp_fit[0].meta.exposure.ngroups\n",
    "group_time = ramp_fit[0].meta.exposure.group_time\n",
    "group_times = np.arange(num_groups) * group_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct linear ramps from the slope and intercept values\n",
    "lin_ramps = np.zeros((jump.shape[1], len(indexes_to_plot)))\n",
    "for counter, idx in enumerate(indexes_to_plot):\n",
    "    #integ, grp, y, x = jump_flags[idx]\n",
    "    y = jump_map_indexes[0][idx]\n",
    "    x = jump_map_indexes[1][idx]\n",
    "    grp = jump_map[0, :, y, x]\n",
    "\n",
    "    rate = ramp_fit[0].data[y, x]\n",
    "    intercept = intercepts[y, x]\n",
    "    lin_ramps[:, counter] = intercept + (rate * group_times)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_data = intercepts[jumpy, jumpx] + (ramp_fit[0].data[jumpy, jumpx] * group_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_jump(jump.data[0, :, jumpy, jumpx], jump_grp, xpixel=jumpx,\n",
    "          ypixel=jumpy, slope=lin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_jumps(jump_data, jump_grps, jump_locs, slopes=lin_ramps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='gain_scale'> The `gain_scale` step </a>\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step applies only to NIRSpec subarray data. It scales rate image values to correct for using a non-standard gain setting.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/gain_scale/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "This step has no optional inputs.\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`GAIN`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/gain_reffile.html) reference file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the run() method\n",
    "gain_scale_step = GainScaleStep()\n",
    "gain_scale_step.output_dir = output_dir\n",
    "gain_scale_step.save_results = True\n",
    "\n",
    "# Call using the dark instance from the previously-run\n",
    "# dark current subtraction step\n",
    "gain_scale = gain_scale_step.run(ramp_fit[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercises'></a>\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MIRI data through the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the supplied MIRI exposure (which can be downloaded in the [Download Data](#download_data) section), run the calwebb_detector1 pipeline, examnine which steps are run, and note the different order compared to the pipeline run above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-run the `reference pixel subtraction` step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try re-running the [reference pixel subtraction](#refpix) step and changing the `side_smoothing_length` and/or `side_gain` parameters. Examine the output to see how well the 1/f noise is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the end of the Stage 1 pipeline. We have now transformed a single exposure from a raw, multiaccum ramp into a signal rate image after applying detector-level corrections. From here, the data move on to the Stage 2 pipeline. For imaging data such as these, that means the *calwebb_image2* pipeline. This will be shown in the Stage 2 notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
